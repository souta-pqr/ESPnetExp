# CER vs DR-CER 比較分析

## 結果サマリー

| 指標 | CER（非流暢現象あり） | DR-CER（非流暢現象削除） | 差分 |
|------|---------------------|----------------------|------|
| Sub (%) | 4.5 | 6.8 | +2.3 |
| Del (%) | 1.5 | 1.6 | +0.1 |
| Ins (%) | 1.3 | 2.4 | +1.1 |
| **総CER (%)** | **7.3** | **10.8** | **+3.5** |

## DR-CERでSub・Insが高くなる理由

### 主な原因

非流暢現象（フィラー・言い直しなど）を削除することで、**モデルが予測した非流暢現象が誤りとしてカウントされる**ようになるため。

---

## 具体例による分析

### 【例1】フィラー「え」「あの」の挿入 → Ins（挿入誤り）の増加

**発話ID: S08M0520_0000264_0003421**

- **元データ（CER）:**
  - REF: `え て ー ま え 何 々 の や り 方 <sp> 何 々 の 作 り 方`
  - HYP: `え て ー ま え 何 々 の や り 方 何 々 の 作 り 方`
  - 誤り: <sp>のDel 1箇所のみ
  
- **非流暢削除後（DR-CER）:**
  - REF: `て ー ま 何 々 の や り 方 <sp> 何 々 の 作 り 方`（「え」×2削除）
  - HYP: `え て ー え 何 々 の や り 方 何 々 の 作 り 方`
  - 誤り: 
    - **Ins「え」（2箇所）** ← モデルが正しくフィラーを予測したが、REFから削除されたため誤りに
    - Sub「ま」→「え」1箇所
    - Del「<sp>」1箇所
  - **CER: 0% → 18.75%に悪化**

---

### 【例2】フィラー「あの」の挿入 → Ins（挿入誤り）の増加

**発話ID: S08M0520_0018095_0023268**

- **元データ（CER）:**
  - REF: `あ の 俗 に 言 う 関 西 風 お 好 み 焼 き と 呼 ば れ て い る <sp> も の が あ る ん す け ど`
  - HYP: `あ の 俗 に 言 う 関 西 風 お 好 み 焼 き と 呼 ば れ て る <sp> も の が あ る ん で す け ど`
  - 誤り: Del「い」、Sub「す」→「で す」程度
  
- **非流暢削除後（DR-CER）:**
  - REF: `俗 に 言 う 関 西 風 お 好 み 焼 き と 呼 ば れ て い る <sp> も の が あ る ん す け ど`（「あ の」削除）
  - HYP: `俗 に 言 う 関 西 風 お 好 み 焼 き と 呼 ば れ て る <sp> も の が あ る ん で す け ど`
  - 誤り:
    - モデルは「あ の」を出力していないが、元データではあったため問題なし
    - この例では偶然、HYPにもフィラーがなかったため影響小

---

### 【例3】フィラー「え」「ま ー」の挿入 → 大幅な誤り増加

**発話ID: S08M0520_0005692_0008132**

- **元データ（CER）:**
  - REF: `え 広 島 風 お 好 み 焼 き の 作 り 方`
  - HYP: `え 広 島 風 岡 の 三 宅 の 作 り 方`
  - 誤り: Sub「お」→「岡」、「好 み 焼 き」→「三 宅」など、内容語の誤り
  
- **非流暢削除後（DR-CER）:**
  - REF: `広 島 風 お 好 み 焼 き の 作 り 方`（「え」削除）
  - HYP: `え 広 島 風 岡 の 三 宅 の 作 り 方`
  - 誤り:
    - **Ins「え」** ← モデルが正しくフィラーを予測したが誤りに
    - Sub「お」→「岡」、「好 み 焼 き」→「三 宅」など
  - **CER: 50%（7 Correct, 4 Sub, 1 Del, 1 Ins）**

---

### 【例4】複数のフィラー「え ー」「あ の ー」

**発話ID: S08M0520_0009988_0014645**

- **元データ（CER）:**
  - REF: `え ー 一 般 的 に <sp> あ の ー お 好 み 焼 き <sp> っ て 言 う と <sp> あ の ー`
  - HYP: `え ー 一 般 的 に <sp> あ の ー お 好 み 焼 き <sp> っ て 言 う と <sp> あ の ー`
  - 誤り: ほぼ完璧に一致
  
- **非流暢削除後（DR-CER）:**
  - REF: `一 般 的 に <sp> お 好 み 焼 き <sp> っ て 言 う と <sp>`（フィラー削除）
  - HYP: `ー 一 般 的 に ー お 好 み 焼 き <sp> っ て 言 う と ー`
  - 誤り:
    - **Ins「ー」（3箇所）** ← 「え ー」「あ の ー」の「ー」が残っている
    - Sub 2箇所
  - **CER: 17.65%に悪化**

---

### 【例5】言い直し・フィラーの組み合わせ

**発話ID: S08M0520_0024181_0026916**

- **元データ（CER）:**
  - REF: `ま そ の ー そ れ は ま ー 小 麦 粉 と ま あ の`
  - HYP: `ま そ の そ れ は ま ー 小 麦 粉 と ま ー あ の`
  - 誤り: Del「ー」1箇所程度
  
- **非流暢削除後（DR-CER）:**
  - REF: `そ れ は 小 麦 粉 と`（フィラー・言い直し削除）
  - HYP: `ま そ そ れ ー 小 麦 粉 の`
  - 誤り:
    - **Ins「ま」「そ」「ー」** ← モデルが予測したフィラーが誤りに
    - Sub「と」→「の」
  - **CER: 57.14%（5 Correct, 2 Sub, 0 Del, 4 Ins）と大幅悪化**

---

## 考察まとめ

### 1. **Ins（挿入誤り）が増加する理由**

- モデルは**訓練時に非流暢現象を学習している**ため、テスト時にも「え」「あの」「ま」「ー」などのフィラーを自然に出力する
- 評価時にREFから非流暢現象を削除すると、モデルが**正しく予測したフィラーが「挿入誤り」としてカウント**される
- 特に以下のフィラーが頻繁に挿入誤りとなる：
  - 「え」「ー」「あ の ー」「ま ー」「え ー」など

### 2. **Sub（置換誤り）が増加する理由**

- フィラーの一部が削除されることで、**アライメントがずれる**
- 例: 「て ー ま」が正解だが、「ま」削除後に「て ー」と「え」がアライメントされ、置換誤りに
- 特に連続するフィラー（「え ー」など）で顕著

### 3. **Del（削除誤り）がほぼ変わらない理由**

- モデルは非流暢現象を**過剰に予測する傾向**があるため、削除誤りは少ない
- むしろ挿入誤りとして現れる

### 4. **全体的な影響**

- **DR-CERが10.8%、通常のCERが7.3%** → **差分3.5ポイント**
- この差分のほとんどが、モデルが正しく予測した非流暢現象が誤りとしてカウントされることによる
- つまり、**モデルの実際の性能は変わっていない**が、**評価基準が変わったことで見かけ上の誤り率が増加**している

---

## 結論

**DR-CERが悪化する主な理由:**

1. **評価指標の定義の違い**: 非流暢現象を含めるか除外するかで、何を「正解」とするかが変わる
2. **モデルの学習内容**: モデルは非流暢現象を含むデータで訓練されているため、テスト時にも自然にフィラーを出力する
3. **アライメントのずれ**: 非流暢現象削除により、REFとHYPの対応関係が崩れ、誤りが増加

**重要な示唆:**

- DR-CERの悪化は必ずしも**モデル性能の低下を意味しない**
- むしろ、モデルが**音声の自然な特徴（非流暢現象）を正しく学習している証拠**とも言える
- タスクの目的に応じて、CERとDR-CERを使い分ける必要がある：
  - **CER**: 音声認識の忠実度（音声をそのまま文字化する能力）
  - **DR-CER**: 内容理解の精度（流暢な読み上げテキストとしての品質）
