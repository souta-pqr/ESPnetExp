config: myconf/train_asr_streaming_transformer.yaml
print_config: false
log_level: INFO
dry_run: false
iterator_type: sequence
output_dir: exp/asr_1204_hatuon_train_cejc_eval_cejc_realtime_fronttag
ngpu: 1
seed: 0
num_workers: 1
num_att_plot: 0
dist_backend: nccl
dist_init_method: env://
dist_world_size: null
dist_rank: null
local_rank: 0
dist_master_addr: null
dist_master_port: null
dist_launcher: null
multiprocessing_distributed: false
unused_parameters: false
sharded_ddp: false
cudnn_enabled: true
cudnn_benchmark: false
cudnn_deterministic: true
collect_stats: false
write_collected_feats: false
max_epoch: 100
patience: 3
val_scheduler_criterion:
- valid
- acc
early_stopping_criterion:
- valid
- cer_ctc
- min
best_model_criterion:
-   - valid
    - acc
    - max
keep_nbest_models: 10
nbest_averaging_interval: 0
grad_clip: 5
grad_clip_type: 2.0
grad_noise: false
accum_grad: 1
no_forward_run: false
resume: true
train_dtype: float32
use_amp: false
log_interval: null
use_matplotlib: true
use_tensorboard: true
create_graph_in_tensorboard: false
use_wandb: false
wandb_project: null
wandb_id: null
wandb_entity: null
wandb_name: null
wandb_model_log_interval: -1
detect_anomaly: false
pretrain_path: null
init_param: []
ignore_init_mismatch: false
freeze_param: []
num_iters_per_epoch: null
batch_size: 64
valid_batch_size: null
batch_bins: 1000000
valid_batch_bins: null
train_shape_file:
- exp/asr_stats_raw_jp_word/train/speech_shape
- exp/asr_stats_raw_jp_word/train/text_shape.word
valid_shape_file:
- exp/asr_stats_raw_jp_word/valid/speech_shape
- exp/asr_stats_raw_jp_word/valid/text_shape.word
batch_type: folded
valid_batch_type: null
fold_length:
- 80000
- 150
sort_in_batch: descending
sort_batch: descending
multiple_iterator: false
chunk_length: 500
chunk_shift_ratio: 0.5
num_cache_chunks: 1024
chunk_excluded_key_prefixes: []
train_data_path_and_name_and_type:
-   - dump/raw/train_nodup/wav.scp
    - speech
    - sound
-   - dump/raw/train_nodup/text
    - text
    - text
valid_data_path_and_name_and_type:
-   - dump/raw/train_dev/wav.scp
    - speech
    - sound
-   - dump/raw/train_dev/text
    - text
    - text
allow_variable_data_keys: false
max_cache_size: 0.0
max_cache_fd: 32
valid_max_cache_size: null
exclude_weight_decay: false
exclude_weight_decay_conf: {}
optim: adam
optim_conf:
    lr: 0.001
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 25000
token_list:
- <blank>
- <unk>
- ー
- ン
- )
- イ
- (I
- ッ
- カ
- ナ
- ウ
- テ
- ト
- ア
- タ
- ノ
- デ
- ダ
- ソ
- コ
- シ
- モ
- ハ
- ラ
- ネ
- ス
- ル
- マ
- ク
- ニ
- レ
- ガ
- ヨ
- オ
- エ
- キ
- サ
- ケ
- ヤ
- ド
- ツ
- (D
- リ
- チ
- ワ
- ミ
- ユ
- (F
- ジ
- ホ
- ジャ
- ロ
- セ
- ゴ
- メ
- バ
- ブ
- チャ
- フ
- ショ
- ヒ
- ヲ
- チョ
- パ
- ジュ
- ゼ
- ベ
- ズ
- ヘ
- グ
- ム
- ゲ
- キョ
- ジョ
- ビ
- シュ
- ボ
- ギ
- シャ
- ザ
- プ
- キュ
- チュ
- ポ
- リョ
- ゾ
- キャ
- ピ
- ヒャ
- ヌ
- ギョ
- ペ
- リャ
- ニュ
- ティ
- ギャ
- ヒョ
- ディ
- ファ
- ビョ
- フォ
- リュ
- フェ
- ジェ
- フィ
- チェ
- ギュ
- ミョ
- ニャ
- ビャ
- ピョ
- トゥ
- ウェ
- ピャ
- ウィ
- ビュ
- ニョ
- シェ
- ウォ
- ミュ
- ピュ
- ドゥ
- ミャ
- ヒュ
- デュ
- ツォ
- ツァ
- ツェ
- イェ
- ヴィ
- ニェ
- ヴォ
- ツィ
- テュ
- スィ
- ガッ
- ヴァ
- ヴ
- フュ
- ヒェ
- <sos/eos>
init: null
input_size: null
ctc_conf:
    dropout_rate: 0.0
    ctc_type: builtin
    reduce: true
    ignore_nan_grad: null
    zero_infinity: true
joint_net_conf: null
use_preprocessor: true
token_type: word
bpemodel: null
non_linguistic_symbols: null
cleaner: null
g2p: null
speech_volume_normalize: null
rir_scp: null
rir_apply_prob: 1.0
noise_scp: null
noise_apply_prob: 1.0
noise_db_range: '13_15'
short_noise_thres: 0.5
aux_ctc_tasks: []
frontend: default
frontend_conf:
    fs: 16k
specaug: null
specaug_conf: {}
normalize: global_mvn
normalize_conf:
    stats_file: exp/asr_stats_raw_jp_word/train/feats_stats.npz
model: espnet
model_conf:
    ctc_weight: 0.3
    lsm_weight: 0.1
    length_normalized_loss: false
preencoder: null
preencoder_conf: {}
encoder: contextual_block_transformer
encoder_conf:
    output_size: 256
    attention_heads: 4
    linear_units: 2048
    num_blocks: 12
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.0
    input_layer: conv2d
    normalize_before: true
    block_size: 40
    hop_size: 16
    look_ahead: 16
    init_average: true
    ctx_pos_enc: true
postencoder: null
postencoder_conf: {}
decoder: transformer
decoder_conf:
    attention_heads: 4
    linear_units: 2048
    num_blocks: 6
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    self_attention_dropout_rate: 0.0
    src_attention_dropout_rate: 0.0
preprocessor: default
preprocessor_conf: {}
required:
- output_dir
- token_list
version: '202304'
distributed: false
